# 进度
## 2021.07.14
尝试了用权重取样和根据label值进行取样，但计算机内存溢出（我的笔记本8g,google colab分配有13g），可能取样方法比普通的随机取样更占内存,去服务器尝试用32g看看行不行。

1. 一张ct拥有n个patch,每个patch通过取样函数进行取样，m个patch组成一个queue,一个queue里又含有多个batch,batch_size只一次训练放入patch的个数。
2. tio.Queue()方法不知道能不能直接取样，因为给出的历程都是在一个subject(里面只有一个label和org)中取样，建议翻阅源码查看。

## 2021.07.15

1. 我写的tansform会爆内存，原来的不会。
2. queue具体实现过程待查阅。
3. pytorch的dataload原理。

下午解答：
1. 没生产一个subject后不能就对其进行transform,应该对集合进行transform,否则内存不够。

2. 对于
   ```
   for i, batch in enumerate(train_loader):
    #affine = batch['label']['affine'].numpy()
    print(i,batch['location'])
    #print(batch)
    ```
    爆内存的原因在于enumerate,尝试用16g内存条可以正常操作，8g会被杀死。

## 2021.07.17

1. 比较了不同的采样方法
```
#WeightedSampler
1 tensor([[178, 267, 329, 242, 331, 393]])
2 tensor([[129, 244, 283, 193, 308, 347]])
3 tensor([[116, 135,   1, 180, 199,  65]])
4 tensor([[117, 315, 259, 181, 379, 323]])
5 tensor([[ 97, 253, 275, 161, 317, 339]])
673.8289363384247

#UniformSampler
1 tensor([[127, 346,  55, 191, 410, 119]])
2 tensor([[261, 237, 409, 325, 301, 473]])
3 tensor([[223, 442, 142, 287, 506, 206]])
4 tensor([[131, 306,  92, 195, 370, 156]])
5 tensor([[103, 390,  16, 167, 454,  80]])
661.3237385749817

```
得出结论：加载慢与采样无关。

2. 由于transform需要把一张ct补充成512*512*512，我觉得时间花在这里，处理器吃不消。
3. 能不能把batch整理成数据集进行训练？
4. 尝试2d网络的分割。
由于2d网络采用的是把三维图片分层，由于有些层没有肿瘤像素，导致采样失败。况且，权重采样不支持二维图像。
5. 采用数据预处理，把数据进行手动大小分割。

1. 由于patch_size太小了，导致分割效果很差。
2. dice的计算原理，相应指标的计算原理。



## 2021.07.18
1.看了肝癌分割，发现别人是用2.5D的方式进行训练，并且训练后，把肝脏以外的像素全部置零，再进行预测。

## 2021.07.19
1. 利用MATLAB把肺分割出来，准备做训练。
2. 利用肺的大小，把肺的ct缩小，这样可以加快训练，但需要实践，还未完成。

## 2021.07.20
1.  训练样本4个，pad = 512,patch = 32, 效果不佳。

折腾了一晚上的总结：
本来想找到一个focal loss 函数，debug了一个晚上也没能弄明白为什么，主要想法：
1. 输出的batch维度为[2 1 64 64 64],我明白后三维应该是图片像素；
2. 发现了一个问题：如果图片全黑，像素都没有，focal loss 还有效吗？
3. focal loss 有一部分就是BCEloss,BCEloss 在 torch.nn里面有定义。
4. bcdloss要把label置为0或者1


想法：把batch搞一下，降维度！


