# 进度
## 2021.07.14
尝试了用权重取样和根据label值进行取样，但计算机内存溢出（我的笔记本8g,google colab分配有13g），可能取样方法比普通的随机取样更占内存,去服务器尝试用32g看看行不行。

1. 一张ct拥有n个patch,每个patch通过取样函数进行取样，m个patch组成一个queue,一个queue里又含有多个batch,batch_size只一次训练放入patch的个数。
2. tio.Queue()方法不知道能不能直接取样，因为给出的历程都是在一个subject(里面只有一个label和org)中取样，建议翻阅源码查看。

## 2021.07.15

1. 我写的tansform会爆内存，原来的不会。
2. queue具体实现过程待查阅。
3. pytorch的dataload原理。

下午解答：
1. 没生产一个subject后不能就对其进行transform,应该对集合进行transform,否则内存不够。

2. 对于
   ```
   for i, batch in enumerate(train_loader):
    #affine = batch['label']['affine'].numpy()
    print(i,batch['location'])
    #print(batch)
    ```
    爆内存的原因在于enumerate,尝试用16g内存条可以正常操作，8g会被杀死。

## 2021.07.17

1. 比较了不同的采样方法
```
#WeightedSampler
1 tensor([[178, 267, 329, 242, 331, 393]])
2 tensor([[129, 244, 283, 193, 308, 347]])
3 tensor([[116, 135,   1, 180, 199,  65]])
4 tensor([[117, 315, 259, 181, 379, 323]])
5 tensor([[ 97, 253, 275, 161, 317, 339]])
673.8289363384247

#UniformSampler
1 tensor([[127, 346,  55, 191, 410, 119]])
2 tensor([[261, 237, 409, 325, 301, 473]])
3 tensor([[223, 442, 142, 287, 506, 206]])
4 tensor([[131, 306,  92, 195, 370, 156]])
5 tensor([[103, 390,  16, 167, 454,  80]])
661.3237385749817

```
得出结论：加载慢与采样无关。

2. 由于transform需要把一张ct补充成512*512*512，我觉得时间花在这里，处理器吃不消。
3. 能不能把batch整理成数据集进行训练？
4. 尝试2d网络的分割。
由于2d网络采用的是把三维图片分层，由于有些层没有肿瘤像素，导致采样失败。况且，权重采样不支持二维图像。
5. 采用数据预处理，把数据进行手动大小分割。

1. 由于patch_size太小了，导致分割效果很差。
2. dice的计算原理，相应指标的计算原理。



## 2021.07.18
1.看了肝癌分割，发现别人是用2.5D的方式进行训练，并且训练后，把肝脏以外的像素全部置零，再进行预测。

## 2021.07.19
1. 利用MATLAB把肺分割出来，准备做训练。
2. 利用肺的大小，把肺的ct缩小，这样可以加快训练，但需要实践，还未完成。

## 2021.07.20
1.  训练样本4个，pad = 512,patch = 32, 效果不佳。

折腾了一晚上的总结：
本来想找到一个focal loss 函数，debug了一个晚上也没能弄明白为什么，主要想法：
1. 输出的batch维度为[2 1 64 64 64],我明白后三维应该是图片像素；
2. 发现了一个问题：如果图片全黑，像素都没有，focal loss 还有效吗？
3. focal loss 有一部分就是BCEloss,BCEloss 在 torch.nn里面有定义。
4. bcdloss要把label置为0或者1


想法：把batch搞一下，降维度！

## 2021.07.29 
重新找了份数据集，进行肺分割时，affine[1,1]会改变，肺分出来的效果不够理想，肺分割在本地进行，分割完成后再传到服务器上，imagesTr为分割好的肺，imagesTs_crop为分割

## 2021.07.30
学会了使用内网穿透（natapp）,但是内网穿透后，我原来的ssh(通过一个网页提供的ssh无法使用，这样使得我每次上传数据和下载数据都及其慢，100k/s)因此我再次重配置了服务器，花了点时间。
第三方提供的服务器，不宜配置ssh.

## 2021.07.31
任务：

- 查阅文献，看别人的环境配置和超参数。
- 总结下数据预处理的流程。 

- 考虑手动crop
 1. 手动crop后可以加快训练；
 2. 我可以用大 batch_size ,采用全局采样，避免小batch_size的权重采样使得其他没被采样的地方效果极差；
 3. test时，网络主要根据训练时的patch_size进行逐步检测，如果训练时一直使用肿瘤附近的patch， 那么检测效果必然差。所以，如果追求好的效果，应该手动crop,然后随机取patch_size(或者整个图片均匀patch),进行训练。（其实我还有一个想法，crop的方法分为0.8label_crop和0.2中心crop,或者随机crop,总之不能全用crop,patch也是类似）.
 

[x] test代码不用label_path也能运行。
[x] 测试过程：patch是均匀采样。


## 2021.08.06
摸鱼了几天，发现模型跑得慢，觉得也没办法，毕竟硬件配置就是比较慢。后续一些想法：
1. 使用手动crop进行数据预处理，这样训练过程会比较快。但是手动crop后，框架的crop就不能使用，patch的方法用只能用随机。因为肿瘤一半都是在肺的边缘，crop后的肿瘤应该在ct边缘，用肿瘤中心patch方法不可行，有些patch无法采样到。
2. 使用nnunet,但是硬件资源不足，等待日后看下资源分配。

## 2021.08.07
突然有这么一想法：
- 把ct分割成512*512*n,n为一个比肿瘤稍微宽的数值
- 让其一张一张得进行训练，减少训练冗余度